{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca9a658",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f73ae6d",
   "metadata": {},
   "source": [
    "# LIME\n",
    "Local Interpretable Model-agnostic Explanations\n",
    "- Can be used for any ML model (agnostic)\n",
    "- Good for black box models (can only see IN and OUT)\n",
    "![alt text](../images/lime_ex.png)\n",
    "- Prediciton made in this example is highly non-linear\n",
    "- The model then learn some complex patterns as a combination of those 2 features.\n",
    "- Therefore, we zoom in to the **local area** and create a simple explanation without taking into account the whole model\n",
    "- LIME fits a linear interpretable model in such area which is often called **surrogate** as well. Creating a local approximation. <br> <br>\n",
    "- Using prior knowledge we can validate the explanations and create trust\n",
    "- ***Cons:***\n",
    "    - Explanations are locally faithful, but not necessarily globally <br>\n",
    "- **Math used in LIME:** <br>\n",
    "$x$ - input data point <br>\n",
    "$f$ - complex model <br>\n",
    "$g$ - Simple interpretable model (**surrogate**) <br>\n",
    "$G$ - Family of interpretable models(linear reg and its variants) <br>\n",
    "$\\pi$ - Defines local neighbourhood of $x$ data point, with some sort of **proximity measure**<br>\n",
    "$\\mathcal{L}(f, g, \\pi_x)$ - we look for an approximation of model $f$ by the simple model $g$ in the neighbourhood of our datapoint x $(\\pi_x)$ <br>\n",
    "$\\Omega(g)$ - regularize (simplify) the complexity of our simple **surrogate model** $(g)$ <br>\n",
    "\n",
    "$$ \\xi(x) = argmin_{g \\in G} \\mathcal{L}(f, g, \\pi_x) + \\Omega(g) $$ <br>\n",
    "- We look for a simple model $g$ that looks for the closest approximation of model $f$, and additionally stay as simple (minimize the complexity) as possible ($\\Omega(g)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b205ef",
   "metadata": {},
   "source": [
    "# LIME: how to train the surrogate\n",
    "![alt text](../images/lime_ex2.png)\n",
    "Steps:\n",
    "1. Generate some new data points in the neighbourhood of our input data point $x$ (yellow points) (they will be weighted according to the distance to our data point)\n",
    "2. This datapoints are generated by permutations (by sampling from a normal distribution with the mean and standard deviation for each feature\n",
    "3. We get the prediction from these data points using our **complex model $f$** so we end up with a new dataset\n",
    "4. The datapoints that are closer (heatmap) to the input $x$ are weighted the most, to ensure the model is locally faithfull\n",
    "5. now, for $\\Omega(g)$, we use a $g = $ **Sparse Linear Model** (aim to produce n zero weights as possible)\n",
    "6. In Practice we could use a regularization technique: **Lasso Regression**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b21c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from interpret.blackbox import LimeTabular\n",
    "from interpret import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93a58c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "path = \"src/healthcare-dataset-stroke-data.csv\"\n",
    "stroke_data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5031a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "# One-hot encode all categorical columns\n",
    "categorical_cols = [\"gender\",\n",
    "                    \"ever_married\",\n",
    "                    \"work_type\",\n",
    "                    \"Residence_type\",\n",
    "                    \"smoking_status\"]\n",
    "encoded = pd.get_dummies(stroke_data[categorical_cols], \n",
    "                        prefix=categorical_cols)\n",
    "\n",
    "# Update data with new columns\n",
    "stroke_data = pd.concat([encoded, stroke_data], axis=1)\n",
    "stroke_data.drop(categorical_cols, axis=1, inplace=True)\n",
    "\n",
    "# Impute missing values of BMI\n",
    "stroke_data.bmi = stroke_data.bmi.fillna(0)\n",
    "        \n",
    "# Drop id as it is not relevant\n",
    "stroke_data.drop([\"id\"], axis=1, inplace=True)\n",
    "\n",
    "# Standardization \n",
    "# Usually we would standardize here and convert it back later\n",
    "# But for simplification we will not standardize / normalize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4666bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data for evaluation\n",
    "def get_data_split(dataset):\n",
    "    X = dataset.iloc[:,:-1]\n",
    "    y = dataset.iloc[:,-1]\n",
    "    return train_test_split(X, y, test_size=0.20, random_state=2021)\n",
    "X_train, X_test, y_train, y_test = get_data_split(stroke_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea726bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample the train data\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "# Convert to numpy and oversample\n",
    "x_np = X_train.to_numpy()\n",
    "y_np = y_train.to_numpy()\n",
    "x_np, y_np = oversample.fit_resample(x_np, y_np)\n",
    "\n",
    "# Convert back to pandas\n",
    "X_train = pd.DataFrame(x_np, columns=X_train.columns)\n",
    "y_train = pd.Series(y_np, name=y_train.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c716b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score 0.5342599524755053\n",
      "Accuracy 0.9452054794520548\n"
     ]
    }
   ],
   "source": [
    "# %% Fit blackbox model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(f\"F1 Score {f1_score(y_test, y_pred, average='macro')}\")\n",
    "print(f\"Accuracy {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c1e4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Apply lime\n",
    "# Initilize Lime for Tabular data\n",
    "lime = LimeTabular(predict_fn=rf.predict_proba, \n",
    "                   data=X_train, \n",
    "                   random_state=1)\n",
    "# Get local explanations\n",
    "lime_local = lime.explain_local(X_test[-20:], \n",
    "                                y_test[-20:], \n",
    "                                name='LIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d264305d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/interpret/visual/udash.py:5: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n",
      "/Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/interpret/visual/udash.py:6: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "/Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/interpret/visual/udash.py:7: UserWarning: \n",
      "The dash_table package is deprecated. Please replace\n",
      "`import dash_table` with `from dash import dash_table`\n",
      "\n",
      "Also, if you're using any of the table format helpers (e.g. Group), replace \n",
      "`from dash_table.Format import Group` with \n",
      "`from dash.dash_table.Format import Group`\n",
      "  import dash_table as dt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7389/140242600498704/ -->\n",
       "<iframe src=\"http://127.0.0.1:7389/140242600498704/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(lime_local)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
