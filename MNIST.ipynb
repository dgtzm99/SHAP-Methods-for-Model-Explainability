{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7cb06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.datasets import load_digits\n",
    "import shap\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline  \n",
    "import tensorflow as tf# tensor flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9bf9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b31f89",
   "metadata": {},
   "source": [
    "## Deep Learning Introduction\n",
    "We want to find mappings to our inputs to some outputs(some neurons) e.g.<br>\n",
    "![alt text](images/deep_learning.jpeg) <br>\n",
    "- each of those connections have their own **unique weight**\n",
    "- 1 Hidden layer $\\rightarrow$ **Neuaral Network**\n",
    "- 2 $\\leq$ x Hidden layer $\\rightarrow$ **Deep Neuaral Network** <br>\n",
    "![alt text](images/deep_learning2.png) <br>\n",
    "- Outputs also have their **Sinusoidal Activation Function as well**, and adding all of them = 1\n",
    "- We take the arg max of those probabilities and that is the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a314e40c",
   "metadata": {},
   "source": [
    "# Load Digits Dataset (MNIST)\n",
    "- Data: 28*28 pxls represented as images of numbers\n",
    "    - Grayscale image: input 0-255 (white-black)\n",
    "- Target: number 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71502e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4223e281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe3ba45aa30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN80lEQVR4nO3df6hcdXrH8c+ncf3DrBpTMYasNhuRWBWbLRqLSl2RrD9QNOqWDVgsBrN/GHChhEr6xyolEuqP0qAsuYu6sWyzLqgYZVkVo6ZFCF5j1JjU1YrdjV6SSozG+KtJnv5xT+Su3vnOzcyZOZP7vF9wmZnzzJnzcLife87Md879OiIEYPL7k6YbANAfhB1IgrADSRB2IAnCDiRxRD83ZpuP/oEeiwiPt7yrI7vtS22/aftt27d281oAesudjrPbniLpd5IWSNou6SVJiyJia2EdjuxAj/XiyD5f0tsR8U5EfCnpV5Ku6uL1APRQN2GfJekPYx5vr5b9EdtLbA/bHu5iWwC61M0HdOOdKnzjND0ihiQNSZzGA03q5si+XdJJYx5/R9L73bUDoFe6CftLkk61/V3bR0r6kaR19bQFoG4dn8ZHxD7bSyU9JWmKpAci4o3aOgNQq46H3jraGO/ZgZ7ryZdqABw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii4ymbcXiYMmVKsX7sscf2dPtLly5tWTvqqKOK686dO7dYv/nmm4v1u+66q2Vt0aJFxXU///zzYn3lypXF+u23316sN6GrsNt+V9IeSfsl7YuIs+toCkD96jiyXxQRH9TwOgB6iPfsQBLdhj0kPW37ZdtLxnuC7SW2h20Pd7ktAF3o9jT+/Ih43/YJkp6x/V8RsWHsEyJiSNKQJNmOLrcHoENdHdkj4v3qdqekxyTNr6MpAPXrOOy2p9o++uB9ST+QtKWuxgDUq5vT+BmSHrN98HX+PSJ+W0tXk8zJJ59crB955JHF+nnnnVesX3DBBS1r06ZNK6577bXXFutN2r59e7G+atWqYn3hwoUta3v27Cmu++qrrxbrL7zwQrE+iDoOe0S8I+kvauwFQA8x9AYkQdiBJAg7kARhB5Ig7EASjujfl9om6zfo5s2bV6yvX7++WO/1ZaaD6sCBA8X6jTfeWKx/8sknHW97ZGSkWP/www+L9TfffLPjbfdaRHi85RzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlrMH369GJ948aNxfqcOXPqbKdW7XrfvXt3sX7RRRe1rH355ZfFdbN+/6BbjLMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJM2VyDXbt2FevLli0r1q+44opi/ZVXXinW2/1L5ZLNmzcX6wsWLCjW9+7dW6yfccYZLWu33HJLcV3UiyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTB9ewD4JhjjinW200vvHr16pa1xYsXF9e9/vrri/W1a9cW6xg8HV/PbvsB2zttbxmzbLrtZ2y/Vd0eV2ezAOo3kdP4X0i69GvLbpX0bEScKunZ6jGAAdY27BGxQdLXvw96laQ11f01kq6uty0Adev0u/EzImJEkiJixPYJrZ5oe4mkJR1uB0BNen4hTEQMSRqS+IAOaFKnQ287bM+UpOp2Z30tAeiFTsO+TtIN1f0bJD1eTzsAeqXtabzttZK+L+l429sl/VTSSkm/tr1Y0u8l/bCXTU52H3/8cVfrf/TRRx2ve9NNNxXrDz/8cLHebo51DI62YY+IRS1KF9fcC4Ae4uuyQBKEHUiCsANJEHYgCcIOJMElrpPA1KlTW9aeeOKJ4roXXnhhsX7ZZZcV608//XSxjv5jymYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9knulFNOKdY3bdpUrO/evbtYf+6554r14eHhlrX77ruvuG4/fzcnE8bZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmTW7hwYbH+4IMPFutHH310x9tevnx5sf7QQw8V6yMjIx1vezJjnB1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHUVnnnlmsX7PPfcU6xdf3Plkv6tXry7WV6xYUay/9957HW/7cNbxOLvtB2zvtL1lzLLbbL9ne3P1c3mdzQKo30RO438h6dJxlv9LRMyrfn5Tb1sA6tY27BGxQdKuPvQCoIe6+YBuqe3XqtP841o9yfYS28O2W/8zMgA912nYfybpFEnzJI1IurvVEyNiKCLOjoizO9wWgBp0FPaI2BER+yPigKSfS5pfb1sA6tZR2G3PHPNwoaQtrZ4LYDC0HWe3vVbS9yUdL2mHpJ9Wj+dJCknvSvpxRLS9uJhx9sln2rRpxfqVV17ZstbuWnl73OHir6xfv75YX7BgQbE+WbUaZz9iAisuGmfx/V13BKCv+LoskARhB5Ig7EAShB1IgrADSXCJKxrzxRdfFOtHHFEeLNq3b1+xfskll7SsPf/888V1D2f8K2kgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLtVW/I7ayzzirWr7vuumL9nHPOaVlrN47eztatW4v1DRs2dPX6kw1HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2SW7u3LnF+tKlS4v1a665plg/8cQTD7mnidq/f3+xPjJS/u/lBw4cqLOdwx5HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2w0C7sexFi8abaHdUu3H02bNnd9JSLYaHh4v1FStWFOvr1q2rs51Jr+2R3fZJtp+zvc32G7ZvqZZPt/2M7beq2+N63y6ATk3kNH6fpL+PiD+X9FeSbrZ9uqRbJT0bEadKerZ6DGBAtQ17RIxExKbq/h5J2yTNknSVpDXV09ZIurpHPQKowSG9Z7c9W9L3JG2UNCMiRqTRPwi2T2ixzhJJS7rsE0CXJhx229+W9Iikn0TEx/a4c8d9Q0QMSRqqXoOJHYGGTGjozfa3NBr0X0bEo9XiHbZnVvWZknb2pkUAdWh7ZPfoIfx+Sdsi4p4xpXWSbpC0srp9vCcdTgIzZswo1k8//fRi/d577y3WTzvttEPuqS4bN24s1u+8886WtccfL//KcIlqvSZyGn++pL+V9LrtzdWy5RoN+a9tL5b0e0k/7EmHAGrRNuwR8Z+SWr1Bv7jedgD0Cl+XBZIg7EAShB1IgrADSRB2IAkucZ2g6dOnt6ytXr26uO68efOK9Tlz5nTSUi1efPHFYv3uu+8u1p966qli/bPPPjvkntAbHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIk04+znnntusb5s2bJiff78+S1rs2bN6qinunz66acta6tWrSque8cddxTre/fu7agnDB6O7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRJpx9oULF3ZV78bWrVuL9SeffLJY37dvX7FeuuZ89+7dxXWRB0d2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjCEVF+gn2SpIcknSjpgKShiPhX27dJuknS/1ZPXR4Rv2nzWuWNAehaRIw76/JEwj5T0syI2GT7aEkvS7pa0t9I+iQi7ppoE4Qd6L1WYZ/I/Owjkkaq+3tsb5PU7L9mAXDIDuk9u+3Zkr4naWO1aKnt12w/YPu4FusssT1se7i7VgF0o+1p/FdPtL8t6QVJKyLiUdszJH0gKST9k0ZP9W9s8xqcxgM91vF7dkmy/S1JT0p6KiLuGac+W9KTEXFmm9ch7ECPtQp729N425Z0v6RtY4NefXB30EJJW7ptEkDvTOTT+Ask/Yek1zU69CZJyyUtkjRPo6fx70r6cfVhXum1OLIDPdbVaXxdCDvQex2fxgOYHAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9HvK5g8k/c+Yx8dXywbRoPY2qH1J9NapOnv7s1aFvl7P/o2N28MRcXZjDRQMam+D2pdEb53qV2+cxgNJEHYgiabDPtTw9ksGtbdB7Uuit071pbdG37MD6J+mj+wA+oSwA0k0Enbbl9p+0/bbtm9toodWbL9r+3Xbm5uen66aQ2+n7S1jlk23/Yztt6rbcefYa6i322y/V+27zbYvb6i3k2w/Z3ub7Tds31Itb3TfFfrqy37r+3t221Mk/U7SAknbJb0kaVFEbO1rIy3YflfS2RHR+BcwbP+1pE8kPXRwai3b/yxpV0SsrP5QHhcR/zAgvd2mQ5zGu0e9tZpm/O/U4L6rc/rzTjRxZJ8v6e2IeCcivpT0K0lXNdDHwIuIDZJ2fW3xVZLWVPfXaPSXpe9a9DYQImIkIjZV9/dIOjjNeKP7rtBXXzQR9lmS/jDm8XYN1nzvIelp2y/bXtJ0M+OYcXCarer2hIb7+bq203j309emGR+YfdfJ9OfdaiLs401NM0jjf+dHxF9KukzSzdXpKibmZ5JO0egcgCOS7m6ymWqa8Uck/SQiPm6yl7HG6asv+62JsG+XdNKYx9+R9H4DfYwrIt6vbndKekyjbzsGyY6DM+hWtzsb7ucrEbEjIvZHxAFJP1eD+66aZvwRSb+MiEerxY3vu/H66td+ayLsL0k61fZ3bR8p6UeS1jXQxzfYnlp9cCLbUyX9QIM3FfU6STdU92+Q9HiDvfyRQZnGu9U042p43zU+/XlE9P1H0uUa/UT+vyX9YxM9tOhrjqRXq583mu5N0lqNntb9n0bPiBZL+lNJz0p6q7qdPkC9/ZtGp/Z+TaPBmtlQbxdo9K3ha5I2Vz+XN73vCn31Zb/xdVkgCb5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D+f1mbt6t55/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359ffa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize (puts values to 0-1) which makes\n",
    "# the neural network easier to learn\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01738b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (60000, 28, 28)\n",
      "y_train:  (60000,)\n",
      "x_test:  (10000, 28, 28)\n",
      "y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train: \", np.shape(x_train))\n",
    "print(\"y_train: \", np.shape(y_train))\n",
    "print(\"x_test: \", np.shape(x_test))\n",
    "print(\"y_test: \", np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80f21a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c33fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:796 train_step\n        loss = self.compiled_loss(\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1712 sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:4979 sparse_categorical_crossentropy\n        res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py:4228 sparse_softmax_cross_entropy_with_logits_v2\n        return sparse_softmax_cross_entropy_with_logits(\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py:4133 sparse_softmax_cross_entropy_with_logits\n        raise ValueError(\"Shape mismatch: The shape of labels (received %s) \"\n\n    ValueError: Shape mismatch: The shape of labels (received (32,)) should equal the shape of logits except for the last dimension (received (21632, 10)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3x/6r8cmlv91b72c0nbcr8p1lhw0000gn/T/ipykernel_7845/3585583820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mseq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    764\u001b[0m             *args, **kwds))\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:796 train_step\n        loss = self.compiled_loss(\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1712 sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:4979 sparse_categorical_crossentropy\n        res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py:4228 sparse_softmax_cross_entropy_with_logits_v2\n        return sparse_softmax_cross_entropy_with_logits(\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/DavidGtz/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py:4133 sparse_softmax_cross_entropy_with_logits\n        raise ValueError(\"Shape mismatch: The shape of labels (received %s) \"\n\n    ValueError: Shape mismatch: The shape of labels (received (32,)) should equal the shape of logits except for the last dimension (received (21632, 10)).\n"
     ]
    }
   ],
   "source": [
    "# 2 types of deep learning models\n",
    "# sequential is most common one\n",
    "seq_model = tf.keras.models.Sequential()\n",
    "# Add our flatten input layer\n",
    "# seq_model.add(tf.keras.layers.Flatten())\n",
    "seq_model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "# Dense(#neurons in layer, activation f(x))\n",
    "# Added two hidden layers\n",
    "seq_model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "seq_model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "# Add our output layer\n",
    "seq_model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "#a NN does not aim to maximize accuracy\n",
    "# NN alwasy tries to minimize loss (degree of error)\n",
    "# so the way to calculate loss impacts greatly the \n",
    "# NN performance\n",
    "seq_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "seq_model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa447b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec89c51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0885 - accuracy: 0.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08850783854722977, 0.9711999893188477)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss, val_acc = seq_model.evaluate(x_test, y_test)\n",
    "val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be59af21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 28, 28) dtype=float32>,)\n",
      "Consider rewriting this model with the Functional API.\n",
      "Model predicted:  5\n",
      "Actual number:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe3a2647af0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seq_model.save('epic_num_reader.model')\n",
    "# load_model = tf.keras.models.load_model('epic_num_reader.model')\n",
    "example = 15\n",
    "pred = seq_model.predict([x_test])\n",
    "# argmax because it is a probability distribution\n",
    "print(\"Model predicted: \",np.argmax(pred[example]))\n",
    "print(\"Actual number:\")\n",
    "plt.imshow(x_test[example], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a41ae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(100, 28, 28), dtype=float64, numpy=\n",
      "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n"
     ]
    }
   ],
   "source": [
    "# SHAP explanation\n",
    "background = x_train[:50] #first examples\n",
    "background = x_train[np.random.choice(x_train.shape[0], 100, replace=False)]\n",
    "explainer = shap.DeepExplainer(seq_model, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b50c8afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'shap_rAnD:0' shape=(200, 28, 28) dtype=float32>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'shap_rAnD:0' shape=(200, 28, 28) dtype=float32>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'shap_rAnD:0' shape=(200, 28, 28) dtype=float32>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'shap_rAnD:0' shape=(200, 28, 28) dtype=float32>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'shap_rAnD:0' shape=(200, 28, 28) dtype=float32>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'shap_rAnD:0' shape=(200, 28, 28) dtype=float32>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'shap_rAnD:0' shape=(200, 28, 28) dtype=float32>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'shap_rAnD:0' shape=(200, 28, 28) dtype=float32>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'shap_rAnD:0' shape=(200, 28, 28) dtype=float32>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'shap_rAnD:0' shape=(200, 28, 28) dtype=float32>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(5, 28, 28), dtype=float64, numpy=\n",
      "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "shap_values = explainer.shap_values(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5326e66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x218.182 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.image_plot(shap_values, -x_test[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6ed2cd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP version is: 0.40.0\n",
      "Tensorflow version is: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(\"SHAP version is:\", shap.__version__)\n",
    "print(\"Tensorflow version is:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c7fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc352a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93611a2a",
   "metadata": {},
   "source": [
    "# Load Digits Dataset (sklearn)\n",
    "- Data: 8*8 pxls represented as images of numbers\n",
    "    - Grayscale image: input 0-16 (white-black)\n",
    "- Target: number 0-9\n",
    "- Samples: 1797 ($\\approx$180 samples per class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823be69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b5bf49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3        0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0        0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1        0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2        0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3        0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4        0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "\n",
       "   pixel_7_6  pixel_7_7  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        9.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3903a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd4e5c78970>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[0:1].to_numpy()\n",
    "plt.imshow(X[0:1].to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
